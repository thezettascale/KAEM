[EbmModel]
layer_widths = 100, 201
spline_degree = 3
layernorm = false
base_activation = leakyrelu
spline_function = RBF
grid_size = 20
grid_update_ratio = 0.05
grid_range = -1.2,1.2
ε_scale = 0.1
μ_scale = 1
σ_base = 1
σ_spline = 1
init_τ = 1.01
τ_trainable = false
π_0 = ebm
GaussQuad_nodes = 100
quadrature_method = gausslegendre
mixture_model = true
λ_reg = 0.0

[GeneratorModel]
widths = 201
spline_degree = 3
layernorm = true
base_activation = silu
spline_function = RBF
grid_size = 1
grid_update_ratio = 0.05
grid_range = -1.2,1.2 
ε_scale = 0.1
μ_scale = 1
σ_base = 1
σ_spline = 1
init_τ = 1
τ_trainable = true
generator_variance = 0.3
generator_noise = 0.3
output_activation = sigmoid
resampler = residual

[GRID_UPDATING]
update_prior_grid = true
update_llhood_grid = false
num_grid_updating_samples = 100
grid_update_frequency = 100
grid_update_decay = 0.999

[PRIOR_LANGEVIN]
step_size = 0.16
iters = 60

[POST_LANGEVIN]
use_langevin = true
initial_step_size = 0.01
step_size_bounds = 0.0001, 10
iters = 40
N_unadjusted = 1
autoMALA_η_changerate = 4
use_autoMALA = false

[THERMODYNAMIC_INTEGRATION]
num_temps = 5
p_start = 6
p_end = 4
num_cycles = 0
N_langevin_per_temp = 40
replica_exchange_frequency = 1

[TRAINING]
batch_size = 100
importance_sample_size = 100
N_train = 40000
N_test = 100
num_generated_samples = 3000
batch_size_for_gen = 100
N_epochs = 10
use_gpu = true
dataset = MNIST
update_grid = true
verbose = true
contrastive_divergence_training = true
resampling_threshold_factor = 0.5
eps = 0.001
checkpoint_every = 4

[MIXED_PRECISION]
full_precision = FP32
reduced_precision = FP32
loss_scaling = 1

[SEQ]
sequence_length = -1
vocab_size = 1000
activation = leakyrelu
d_model = 128

[CNN]
use_cnn_lkhood = true
hidden_feature_dims = 1024, 512, 256
strides = 1, 2, 2, 1
kernel_sizes = 8, 4, 4, 3
paddings = 0, 1, 1, 1
activation = leakyrelu
batchnorm = false

[OPTIMIZER]
type = adam
learning_rate = 0.0002
l-bfgs_memory = 100

[LINE_SEARCH]
type = morethuente
c_1 = 1e-4
c_2 = 0.9
rho = 0.5
